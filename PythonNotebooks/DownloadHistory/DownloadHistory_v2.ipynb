{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt at downloading all scrobbled songs from LastFM and formatting them\n",
    "\n",
    "Aim of attempt 1 is to get a formatted pandas dataframe of information to be refactored later\n",
    "Initial Requirements are:\n",
    "Song name\n",
    "Artist name\n",
    "Date and time of song playing\n",
    "\n",
    "Got working on single page and tested on many - now refactoring across many pages.\n",
    "\n",
    "Later requirements will include login, error check and be parameterised so it works for other users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do list\n",
    "\n",
    "- (done) Get cleaner artist and timestamp scrape \n",
    "- (done) Loop over all last fm songs\n",
    "- (done) Remove song titles after \"-\" as it is normally something like \"remastered\" \n",
    "- (done) Export data\n",
    "- (done) Create field that is current timestamp (needed to refactor time later\n",
    "- (done) Refactor\n",
    "- Do I need to login for this to work?\n",
    "- Save to G drive at the end of the day!\n",
    "\n",
    "### To-do list moved to another notebook, part of data preparation\n",
    "- Get better time stamp format and transform \"hours since\" timings (see last block of commented code)\n",
    "- Get time between songs and flag skipped songs\n",
    "- Make some generic time features (time of day, weekend etc.)\n",
    "- Bring in metadata for songs\n",
    "\n",
    "## For future iterations\n",
    "\n",
    "- Login to lastfm (if required)\n",
    "- Make part of a managed folder (must learn how first...)\n",
    "- Append new data don't keep recreating whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re           # regular expressions\n",
    "import requests     # request web pages\n",
    "import bs4          # 'beautiful soup 4' - find elements within HTML\n",
    "import lxml         # HTML parser\n",
    "import pandas as pd # allows making dataframes of results\n",
    "import numpy as np\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## user input parameters\n",
    "lastfm_username_list = ['COKUNUBI','rosiedempsey93']\n",
    "\n",
    "## last fm determined parameters\n",
    "\n",
    "# start and end of URL\n",
    "lastfm_starturl = 'https://www.last.fm/user/'\n",
    "lastfm_endurl = '/library?date_preset=ALL&page='\n",
    "\n",
    "# headers for dataframe\n",
    "column_names = ['song', 'artist', 'play_time']\n",
    "\n",
    "# where data exports to\n",
    "export_path_version = \"/Users/rosiedempsey/Desktop/MusicProject/finely_tuned/DataExports/RawScrobbles_\"+str(date.today())+\".csv\"\n",
    "export_path_master = \"/Users/rosiedempsey/Desktop/MusicProject/finely_tuned/DataExports/RawScrobbles_master.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find links for all pages containing songs\n",
    "# First find the number of pages\n",
    "# function find maximum page\n",
    "def find_max_page(lastfm_page, lastfm_username):\n",
    "    \"\"\"\n",
    "    Open any lastfm music page and  req then soup to get max page\n",
    "    \"\"\"\n",
    "    lastfm_example_page = lastfm_starturl+lastfm_username+lastfm_endurl+'2'\n",
    "    example_req = requests.get(lastfm_example_page)\n",
    "    example_soup = bs4.BeautifulSoup(example_req.text, \"lxml\")\n",
    "    pages_list = []\n",
    "    for item in example_soup.find_all(\"li\",{\"class\":\"pagination-page\"}):\n",
    "        try:\n",
    "            pages_list.append(int(item.text.strip('\\n')))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    print(\"max page: \"+str(max(pages_list)))\n",
    "    return max(pages_list)\n",
    "\n",
    "# Make list of all pages\n",
    "# Function for making list\n",
    "def all_pages_list(max_page, lastfm_username):\n",
    "    lastfm_base = lastfm_starturl + lastfm_username + lastfm_endurl\n",
    "    page_list = []\n",
    "    for i in range(1,max_page+1):\n",
    "        page_list.append(lastfm_base+str(i))\n",
    "    return page_list\n",
    "\n",
    "# Make list of requests and soups for all pages\n",
    "# make function for a list of webapges\n",
    "def cooking_many_soup(page_list):\n",
    "    \"\"\"\n",
    "    First request all the pages and store requests in list\n",
    "    The iterate of list of requests to make list of soups\n",
    "    Output is a list\n",
    "    \"\"\"\n",
    "    many_requests = []\n",
    "    for page in page_list:\n",
    "        many_requests.append(requests.get(page))\n",
    "    \n",
    "    many_soup = []\n",
    "    for req in many_requests:\n",
    "        many_soup.append(bs4.BeautifulSoup(req.text, \"lxml\"))\n",
    "    \n",
    "    return many_soup\n",
    "\n",
    "\n",
    "# return a list for each bit of information we want (artist, song, time)\n",
    "\n",
    "# songs - remove new line characters and anything after a \"-\" as it is normally something like \"remasterd 1999\"\n",
    "# function\n",
    "def get_songs_list(many_soup):\n",
    "    song_list= []\n",
    "    for soup in many_soup:\n",
    "        for item in soup.find_all(\"td\",{\"class\":\"chartlist-name\"}):\n",
    "            song_list.append(item.text.replace(\"\\n\", \"\").partition(\"-\")[0])\n",
    "    return song_list\n",
    "\n",
    "# artists\n",
    "# function\n",
    "def get_artist_list(many_soup):\n",
    "    artist_list= []\n",
    "    for soup in many_soup:\n",
    "        for item in soup.find_all(\"td\",{\"class\":\"chartlist-artist\"}):\n",
    "            artist_list.append(item.text.replace(\"\\n\", \"\"))\n",
    "    return artist_list\n",
    "\n",
    "# timestamps\n",
    "# function\n",
    "def get_timestamp_list(many_soup):\n",
    "    timestamp_list= []\n",
    "    for soup in many_soup:\n",
    "        for item in soup.find_all(\"td\",{\"class\":\"chartlist-timestamp\"}):\n",
    "            timestamp_list.append(item.text.replace(\"\\n\", \"\").replace(\" \", \"\").replace(\"\\xa0\", \"\"))\n",
    "    return timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline functions\n",
    "def scrape_listening_history(lastfm_username):\n",
    "    \"\"\"\n",
    "    Make soup for one page with chosen username and check\n",
    "    Find max_page for that user\n",
    "    Make list of all urls\n",
    "    Apply soupy function\n",
    "    Get required data: songs, artists, timestamp and save\n",
    "    \"\"\"\n",
    "    lastfm_example_page = lastfm_starturl+lastfm_username+lastfm_endurl+'2'\n",
    "    example_req = requests.get(lastfm_example_page)\n",
    "    print(\"Error status: \"+str(example_req.raise_for_status()))    # returns error if page not found\n",
    "    max_page = find_max_page(lastfm_example_page,lastfm_username)\n",
    "    all_pages = all_pages_list(max_page,lastfm_username)\n",
    "    my_soups = cooking_many_soup(all_pages)\n",
    "    \n",
    "    my_songs = get_songs_list(my_soups)\n",
    "    my_artists = get_artist_list(my_soups)\n",
    "    my_times = get_timestamp_list(my_soups)\n",
    "    my_list = [my_songs,my_artists,my_times]\n",
    "    return my_list\n",
    "\n",
    "def make_history_dataframe(scraped_data, data_headers, lastfm_username):\n",
    "    \"\"\"\n",
    "    Make pandas dataframe scraped data\n",
    "    Add a download time field\n",
    "    \"\"\"\n",
    "    my_scrobbles = pd.DataFrame(np.column_stack(scraped_data), \n",
    "                                   columns=data_headers)\n",
    "    my_scrobbles['download_time'] = datetime.now()\n",
    "    my_scrobbles['username'] = lastfm_username\n",
    "    return my_scrobbles\n",
    "\n",
    "def export_history(scrobbles_df, export_path_version, export_path_master):\n",
    "    \"\"\"\n",
    "    Export a versioned and master of the data\n",
    "    Contains user name\n",
    "    \"\"\"\n",
    "    scrobbles_df.to_csv(export_path_version, index=False)\n",
    "    scrobbles_df.to_csv(export_path_master, index=False)\n",
    "\n",
    "\n",
    "def export_multiple_histories_pipeline(lastfm_username_list,column_names,export_path_version,export_path_master):\n",
    "    \"\"\"\n",
    "    Takes any usernames listed\n",
    "    Scrapes their data into a pandas dataframe and exports\n",
    "    \"\"\"\n",
    "    scrobbles_dfs = []\n",
    "    for last_fm_username in lastfm_username_list:\n",
    "        scraped_data = scrape_listening_history(last_fm_username)\n",
    "        scraped_df = make_history_dataframe(scraped_data,column_names,last_fm_username)\n",
    "        scrobbles_dfs.append(scraped_df)\n",
    "        # see pd.concat documentation for more info\n",
    "    all_scrobbles = pd.concat(scrobbles_dfs)\n",
    "    export_history(all_scrobbles, export_path_version, export_path_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error status: None\n",
      "max page: 419\n"
     ]
    }
   ],
   "source": [
    "export_multiple_histories_pipeline(lastfm_username_list,column_names,export_path_version,export_path_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test = pd.read_csv(export_path_version)\n",
    "read_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
