{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second attempt at downloading all scrobbled songs from LastFM and formatting them\n",
    "\n",
    "Aim of attempt 1 is to get a formatted pandas dataframe of information to be refactored later\n",
    "Initial Requirements are:\n",
    "Song name\n",
    "Artist name\n",
    "Date and time of song playing\n",
    "\n",
    "Got working on single page and tested on many - now refactoring across many pages.\n",
    "\n",
    "Later requirements will include login, error check and be parameterised so it works for other users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do list\n",
    "\n",
    "- (done) Get cleaner artist and timestamp scrape \n",
    "- (done) Loop over all last fm songs\n",
    "- (done) Remove song titles after \"-\" as it is normally something like \"remastered\" \n",
    "- (done) Export data\n",
    "- (done) Create field that is current timestamp (needed to refactor time later\n",
    "- (done) Refactor\n",
    "- Do I need to login for this to work?\n",
    "- Save to G drive at the end of the day!\n",
    "\n",
    "### To-do list moved to another notebook, part of data preparation\n",
    "- Get better time stamp format and transform \"hours since\" timings (see last block of commented code)\n",
    "- Get time between songs and flag skipped songs\n",
    "- Make some generic time features (time of day, weekend etc.)\n",
    "- Bring in metadata for songs\n",
    "\n",
    "## For future iterations\n",
    "\n",
    "- Login to lastfm (if required)\n",
    "- Make part of a managed folder (must learn how first...)\n",
    "- Append new data don't keep recreating whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re           # regular expressions\n",
    "import requests     # request web pages\n",
    "import bs4          # 'beautiful soup 4' - find elements within HTML\n",
    "import lxml         # HTML parser\n",
    "import pandas as pd # allows making dataframes of results\n",
    "import numpy as np\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## user input parameters\n",
    "lastfm_username = 'COKUNUBI'\n",
    "\n",
    "## last fm determined parameters\n",
    "\n",
    "# get \"base page\" for a given username\n",
    "# a number is required at the end for each page of songs\n",
    "\n",
    "# this is an example of one the urls we need\n",
    "lastfm_example_page = 'https://www.last.fm/user/rosiedempsey93/library?date_preset=ALL&page=2'\n",
    "\n",
    "# start and end of URL\n",
    "lastfm_starturl = 'https://www.last.fm/user/'\n",
    "lastfm_endurl = '/library?date_preset=ALL&page='\n",
    "lastfm_base = lastfm_starturl + lastfm_username + lastfm_endurl\n",
    "\n",
    "# where data exports to\n",
    "export_path_version = \"/Users/rosiedempsey/Desktop/MusicProject/finely_tuned/DataExports/RawScrobbles_\"+str(date.today())+\".csv\"\n",
    "export_path_master = \"/Users/rosiedempsey/Desktop/MusicProject/finely_tuned/DataExports/RawScrobbles_master.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find links for all pages containing songs\n",
    "# First find the number of pages\n",
    "# function find maximum page\n",
    "def find_max_page(lastfm_page):\n",
    "    \"\"\"\n",
    "    Open any lastfm music page and  req then soup to get max page\n",
    "    \"\"\"\n",
    "    example_req = requests.get(lastfm_example_page)\n",
    "    example_soup = bs4.BeautifulSoup(example_req.text, \"lxml\")\n",
    "    pages_list = []\n",
    "    for item in example_soup.find_all(\"li\",{\"class\":\"pagination-page\"}):\n",
    "        try:\n",
    "            pages_list.append(int(item.text.strip('\\n')))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return max(pages_list)\n",
    "\n",
    "# Make list of all pages\n",
    "# Function for making list\n",
    "def all_pages_list(max_page):\n",
    "    page_list = []\n",
    "    for i in range(1,max_page+1):\n",
    "        page_list.append(lastfm_base+str(i))\n",
    "    return page_list\n",
    "\n",
    "# Make list of requests and soups for all pages\n",
    "# make function for a list of webapges\n",
    "def cooking_many_soup(page_list):\n",
    "    \"\"\"\n",
    "    First request all the pages and store requests in list\n",
    "    The iterate of list of requests to make list of soups\n",
    "    Output is a list\n",
    "    \"\"\"\n",
    "    many_requests = []\n",
    "    for page in page_list:\n",
    "        many_requests.append(requests.get(page))\n",
    "    \n",
    "    many_soup = []\n",
    "    for req in many_requests:\n",
    "        many_soup.append(bs4.BeautifulSoup(req.text, \"lxml\"))\n",
    "    \n",
    "    return many_soup\n",
    "\n",
    "\n",
    "# return a list for each bit of information we want (artist, song, time)\n",
    "\n",
    "# songs - remove new line characters and anything after a \"-\" as it is normally something like \"remasterd 1999\"\n",
    "# function\n",
    "def get_songs_list(many_soup):\n",
    "    song_list= []\n",
    "    for soup in many_soup:\n",
    "        for item in soup.find_all(\"td\",{\"class\":\"chartlist-name\"}):\n",
    "            song_list.append(item.text.replace(\"\\n\", \"\").partition(\"-\")[0])\n",
    "    return song_list\n",
    "\n",
    "# artists\n",
    "# function\n",
    "def get_artist_list(many_soup):\n",
    "    artist_list= []\n",
    "    for soup in many_soup:\n",
    "        for item in soup.find_all(\"td\",{\"class\":\"chartlist-artist\"}):\n",
    "            artist_list.append(item.text.replace(\"\\n\", \"\"))\n",
    "    return artist_list\n",
    "\n",
    "# timestamps\n",
    "# function\n",
    "def get_timestamp_list(many_soup):\n",
    "    timestamp_list= []\n",
    "    for soup in many_soup:\n",
    "        for item in soup.find_all(\"td\",{\"class\":\"chartlist-timestamp\"}):\n",
    "            timestamp_list.append(item.text.replace(\"\\n\", \"\").replace(\" \", \"\").replace(\"\\xa0\", \"\"))\n",
    "    return timestamp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# check page works for page 1 and make BS for 1 page\n",
    "# Request the page, check it is valid and parse.\n",
    "example_req = requests.get(lastfm_example_page)\n",
    "print(example_req.raise_for_status())    # returns error if page not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "# Find max_page\n",
    "max_page = find_max_page(lastfm_example_page)\n",
    "print(max_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.last.fm/user/COKUNUBI/library?date_preset=ALL&page=67'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make list \n",
    "# all_pages = all_pages_list(max_page)\n",
    "# For testing purposes on a smaller number\n",
    "all_pages = all_pages_list(max_page)\n",
    "all_pages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply soupy function\n",
    "my_soups = cooking_many_soup(all_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3350\n",
      "Sagana\n"
     ]
    }
   ],
   "source": [
    "# apply  songs function\n",
    "my_songs = get_songs_list(my_soups)\n",
    "\n",
    "# check\n",
    "print(len(my_songs))\n",
    "print(my_songs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3350\n",
      "Rupert Gregson-Williams\n"
     ]
    }
   ],
   "source": [
    "# apply artistsfunction\n",
    "my_artists = get_artist_list(my_soups)\n",
    "\n",
    "# check\n",
    "print(len(my_artists))\n",
    "print(my_artists[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3350\n",
      "2hoursago\n"
     ]
    }
   ],
   "source": [
    "# apply timestamp function\n",
    "my_times = get_timestamp_list(my_soups)\n",
    "\n",
    "# check\n",
    "print(len(my_times))\n",
    "print(my_times[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>play_time</th>\n",
       "      <th>download_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>Buddy</td>\n",
       "      <td>Du Blonde</td>\n",
       "      <td>13Jul3:58pm</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>Inbetweener</td>\n",
       "      <td>Sleeper</td>\n",
       "      <td>13Jul3:54pm</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>Atomic</td>\n",
       "      <td>Sleeper</td>\n",
       "      <td>13Jul3:49pm</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>Clownfish</td>\n",
       "      <td>Hans Zimmer</td>\n",
       "      <td>12Jul9:52am</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>Kobudai Transformation</td>\n",
       "      <td>Hans Zimmer</td>\n",
       "      <td>12Jul9:46am</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        song       artist    play_time  \\\n",
       "3345                   Buddy    Du Blonde  13Jul3:58pm   \n",
       "3346             Inbetweener      Sleeper  13Jul3:54pm   \n",
       "3347                  Atomic      Sleeper  13Jul3:49pm   \n",
       "3348               Clownfish  Hans Zimmer  12Jul9:52am   \n",
       "3349  Kobudai Transformation  Hans Zimmer  12Jul9:46am   \n",
       "\n",
       "                  download_time  \n",
       "3345 2019-08-22 19:30:53.125480  \n",
       "3346 2019-08-22 19:30:53.125480  \n",
       "3347 2019-08-22 19:30:53.125480  \n",
       "3348 2019-08-22 19:30:53.125480  \n",
       "3349 2019-08-22 19:30:53.125480  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# makes data frame of scrapes that align \n",
    "my_lists = [my_songs,my_artists,my_times]\n",
    "my_coulm_names = ['song', 'artist', 'play_time']\n",
    "my_scrobbles = pd.DataFrame(np.column_stack(my_lists), \n",
    "                               columns=my_coulm_names)\n",
    "my_scrobbles['download_time'] = datetime.now()\n",
    "my_scrobbles.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3350"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scrobbles.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dated version and replace old version\n",
    "my_scrobbles.to_csv(export_path_version, index=False)\n",
    "my_scrobbles.to_csv(export_path_master, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>play_time</th>\n",
       "      <th>download_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Government</td>\n",
       "      <td>Rupert Gregson-Williams</td>\n",
       "      <td>2hoursago</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sagana</td>\n",
       "      <td>Rupert Gregson-Williams</td>\n",
       "      <td>2hoursago</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck Shoot</td>\n",
       "      <td>Rupert Gregson-Williams</td>\n",
       "      <td>2hoursago</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Crown Main Title</td>\n",
       "      <td>Hans Zimmer</td>\n",
       "      <td>2hoursago</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Government</td>\n",
       "      <td>Rupert Gregson-Williams</td>\n",
       "      <td>2hoursago</td>\n",
       "      <td>2019-08-22 19:30:53.125480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song                   artist  play_time  \\\n",
       "0            Government  Rupert Gregson-Williams  2hoursago   \n",
       "1                Sagana  Rupert Gregson-Williams  2hoursago   \n",
       "2            Duck Shoot  Rupert Gregson-Williams  2hoursago   \n",
       "3  The Crown Main Title              Hans Zimmer  2hoursago   \n",
       "4            Government  Rupert Gregson-Williams  2hoursago   \n",
       "\n",
       "                download_time  \n",
       "0  2019-08-22 19:30:53.125480  \n",
       "1  2019-08-22 19:30:53.125480  \n",
       "2  2019-08-22 19:30:53.125480  \n",
       "3  2019-08-22 19:30:53.125480  \n",
       "4  2019-08-22 19:30:53.125480  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_test = pd.read_csv(export_path_version)\n",
    "read_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
